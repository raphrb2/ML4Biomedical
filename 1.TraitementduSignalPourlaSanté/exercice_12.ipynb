{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pP3htYzA2Gv"
      },
      "source": [
        "# Exercice 12:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gxa8xshgSeW"
      },
      "source": [
        "## Création d'un CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WzN9jVCTGVh"
      },
      "source": [
        "[lien Nowledgeable](https://nowledgeable.com/invitation/student/join-module/9c8ec467-686a-44cd-a2f2-85cf174a79ad) <br>\n",
        "A l'aide de la transformée en ondelettes continue, transformez des signaux ECG en scaleograms et puis utilisez un modèle CNN pour classifier des images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-09-25T19:30:06.043114Z",
          "iopub.status.busy": "2023-09-25T19:30:06.042571Z",
          "iopub.status.idle": "2023-09-25T19:30:22.237888Z",
          "shell.execute_reply": "2023-09-25T19:30:22.236396Z",
          "shell.execute_reply.started": "2023-09-25T19:30:06.043073Z"
        },
        "id": "wWhXzRJehB_8",
        "outputId": "7daa107c-8762-4d76-f220-9bbedd5aa0cb",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wfdb\n",
            "  Downloading wfdb-4.1.2-py3-none-any.whl (159 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.0/160.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: SoundFile>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from wfdb) (0.12.1)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from wfdb) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.10.1 in /usr/local/lib/python3.10/dist-packages (from wfdb) (1.23.5)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from wfdb) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from wfdb) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wfdb) (1.11.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->wfdb) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8.1->wfdb) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8.1->wfdb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8.1->wfdb) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8.1->wfdb) (2023.7.22)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from SoundFile>=0.10.0->wfdb) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->SoundFile>=0.10.0->wfdb) (2.21)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->wfdb) (1.16.0)\n",
            "Installing collected packages: wfdb\n",
            "Successfully installed wfdb-4.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wfdb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XbfYgoRgSeZ"
      },
      "source": [
        "## Imports des librairies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-25T19:39:14.804684Z",
          "iopub.status.busy": "2023-09-25T19:39:14.804207Z",
          "iopub.status.idle": "2023-09-25T19:39:15.193029Z",
          "shell.execute_reply": "2023-09-25T19:39:15.191583Z",
          "shell.execute_reply.started": "2023-09-25T19:39:14.804653Z"
        },
        "id": "y1jrUS_RhFpM",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "import wfdb\n",
        "import pywt\n",
        "from scipy import signal as scipy_signal\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VgEjdpLgSeZ"
      },
      "source": [
        "Afin de pouvoir récupérer les signaux issus des datasets de physionet, utilisons `load_signal_using_wfdb`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-25T19:30:33.142339Z",
          "iopub.status.busy": "2023-09-25T19:30:33.140884Z",
          "iopub.status.idle": "2023-09-25T19:30:33.150347Z",
          "shell.execute_reply": "2023-09-25T19:30:33.148607Z",
          "shell.execute_reply.started": "2023-09-25T19:30:33.142300Z"
        },
        "id": "sCw4fb5bhHKt",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def load_signal_using_wfdb(file, start, end, channel, pn_dir):\n",
        "    record = wfdb.rdrecord(file, sampfrom = start, sampto = end, channels=[channel], pn_dir=pn_dir)\n",
        "    data = record.p_signal.reshape(-1)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-25T19:30:33.153164Z",
          "iopub.status.busy": "2023-09-25T19:30:33.152609Z",
          "iopub.status.idle": "2023-09-25T19:30:33.170687Z",
          "shell.execute_reply": "2023-09-25T19:30:33.168423Z",
          "shell.execute_reply.started": "2023-09-25T19:30:33.153121Z"
        },
        "id": "vDCqRlgFgSea",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# recupération des donnees\n",
        "database_names = ['nsrdb','mitdb','chfdb']\n",
        "n_label = len(database_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-25T19:30:33.176015Z",
          "iopub.status.busy": "2023-09-25T19:30:33.175491Z",
          "iopub.status.idle": "2023-09-25T19:30:34.771912Z",
          "shell.execute_reply": "2023-09-25T19:30:34.770379Z",
          "shell.execute_reply.started": "2023-09-25T19:30:33.175939Z"
        },
        "id": "mH8f_88hgSea",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# recupération des noms des fichiers et des labels\n",
        "record_names = []\n",
        "labels = []\n",
        "\n",
        "for i, name in enumerate(database_names):\n",
        "    current_record_names = wfdb.get_record_list(name)\n",
        "    record_names += current_record_names\n",
        "    labels += [i] * len(current_record_names)\n",
        "\n",
        "assert len(record_names) == len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-25T19:38:06.949681Z",
          "iopub.status.busy": "2023-09-25T19:38:06.949213Z",
          "iopub.status.idle": "2023-09-25T19:38:44.020468Z",
          "shell.execute_reply": "2023-09-25T19:38:44.018798Z",
          "shell.execute_reply.started": "2023-09-25T19:38:06.949648Z"
        },
        "id": "wNZsJr1IgSea",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "frequencies = []\n",
        "for record_name, label in zip(record_names, labels):\n",
        "    header = wfdb.rdheader(record_name, database_names[label])\n",
        "    frequencies.append(header.fs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-25T19:47:58.770358Z",
          "iopub.status.busy": "2023-09-25T19:47:58.769899Z",
          "iopub.status.idle": "2023-09-25T19:47:58.778690Z",
          "shell.execute_reply": "2023-09-25T19:47:58.776998Z",
          "shell.execute_reply.started": "2023-09-25T19:47:58.770325Z"
        },
        "id": "wSU8N0m1gSea",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def resample_signal(input_signal, original_rate, target_rate):\n",
        "\n",
        "    # Calculating the number of samples in the resampled signal\n",
        "    num_samples = int((target_rate * len(input_signal)) / original_rate)\n",
        "\n",
        "    # Resampling the input signal to match the target sampling rate\n",
        "    resampled_signal = scipy_signal.resample(input_signal, num_samples)\n",
        "\n",
        "    return resampled_signal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUwNZTEHgSeb"
      },
      "source": [
        "Passons à l'extraction de la donnée:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-25T20:07:57.363267Z",
          "iopub.status.busy": "2023-09-25T20:07:57.362728Z",
          "iopub.status.idle": "2023-09-25T20:07:57.378744Z",
          "shell.execute_reply": "2023-09-25T20:07:57.377057Z",
          "shell.execute_reply.started": "2023-09-25T20:07:57.363231Z"
        },
        "id": "mw9-dCaBgSeb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def generate_data(sample_size, scale_size, nb_samples_per_signal, labels, record_names, database_names, file_path=None, frequencies=[], common_sampling_rate=128):\n",
        "\n",
        "    scales = range(1, scale_size + 1)\n",
        "    waveletname = 'morl'\n",
        "    signal_ds = []\n",
        "    y_train = np.zeros(nb_samples_per_signal * len(labels))\n",
        "    num_records = len(record_names)\n",
        "\n",
        "    # Charger et traiter les signaux\n",
        "    for i in range(num_records):\n",
        "        record_name, label, frequency = record_names[i], labels[i], frequencies[i]\n",
        "        pn_dir = database_names[label]\n",
        "        signal = load_signal_using_wfdb(record_name, start=0, end=nb_samples_per_signal * frequency, channel=0, pn_dir=pn_dir)\n",
        "        signal = resample_signal(signal, frequency, common_sampling_rate)\n",
        "        signal_ds.extend(np.split(signal, nb_samples_per_signal))\n",
        "        y_train[i * nb_samples_per_signal: (i + 1) * nb_samples_per_signal] = label\n",
        "\n",
        "    signal_ds = np.array(signal_ds)\n",
        "\n",
        "    # Calcul des coefficients de transformation en ondelette continue\n",
        "    X_train = [pywt.cwt(signal, scales, waveletname, 1)[0] for signal in signal_ds]\n",
        "    X_train = np.expand_dims(X_train, axis=-1)\n",
        "    X_tensor = tf.convert_to_tensor(X_train)\n",
        "\n",
        "    # Conversion des étiquettes en encodage one-hot et création d'un tenseur\n",
        "    num_classes = len(np.unique(y_train))\n",
        "    y_tensor = tf.convert_to_tensor(tf.keras.utils.to_categorical(y_train, num_classes))\n",
        "\n",
        "    return X_tensor, y_tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-25T20:15:22.841458Z",
          "iopub.status.busy": "2023-09-25T20:15:22.840999Z",
          "iopub.status.idle": "2023-09-25T20:16:40.807699Z",
          "shell.execute_reply": "2023-09-25T20:16:40.805998Z",
          "shell.execute_reply.started": "2023-09-25T20:15:22.841426Z"
        },
        "id": "R1SaPFdegSeb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "sample_size = 64\n",
        "scale_size = 64\n",
        "nb_samples_per_signal = 64\n",
        "common_sampling_rate = 64\n",
        "\n",
        "X_tensor, y_tensor = generate_data(sample_size = sample_size,scale_size = scale_size,nb_samples_per_signal = nb_samples_per_signal, labels= labels, record_names = record_names,database_names=database_names,file_path='signals_csv',frequencies = frequencies ,common_sampling_rate = common_sampling_rate)\n",
        "assert X_tensor.shape[0] == y_tensor.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-09-25T20:17:58.787272Z",
          "iopub.status.busy": "2023-09-25T20:17:58.786836Z",
          "iopub.status.idle": "2023-09-25T20:17:58.958545Z",
          "shell.execute_reply": "2023-09-25T20:17:58.957457Z",
          "shell.execute_reply.started": "2023-09-25T20:17:58.787239Z"
        },
        "id": "8fPYQdbKgSec",
        "outputId": "f4d338b8-2018-44bd-ed14-b3d21712062b",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 60, 60, 64)        1664      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 30, 30, 64)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 30, 30, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 28, 28, 32)        18464     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 14, 14, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 14, 14, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 12, 12, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 6, 6, 32)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1152)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               147584    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 177347 (692.76 KB)\n",
            "Trainable params: 177347 (692.76 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import  Dense, Dropout, Conv2D, Input, MaxPooling2D,Flatten\n",
        "\n",
        "def build_model(input_shape,num_class):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=input_shape))\n",
        "\n",
        "    model.add(Conv2D(filters=64,kernel_size=5, activation='relu'))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Conv2D(filters=32,kernel_size=3, activation='relu'))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Conv2D(filters=32,kernel_size=3, activation='relu'))\n",
        "    model.add(MaxPooling2D())\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(num_class,activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "    return model\n",
        "model = build_model(X_tensor.shape[1:],y_tensor.shape[1])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-09-25T20:17:09.796293Z",
          "iopub.status.busy": "2023-09-25T20:17:09.795534Z",
          "iopub.status.idle": "2023-09-25T20:17:09.805431Z",
          "shell.execute_reply": "2023-09-25T20:17:09.803907Z",
          "shell.execute_reply.started": "2023-09-25T20:17:09.796253Z"
        },
        "id": "-o7CHt_TgSec",
        "outputId": "95e07ea8-18cd-48f5-e9f6-0b55d56ba54d",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(TensorShape([5184, 64, 64, 1]), TensorShape([5184, 3]))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_tensor.shape,y_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-09-25T20:18:02.674504Z",
          "iopub.status.busy": "2023-09-25T20:18:02.674053Z",
          "iopub.status.idle": "2023-09-25T20:19:05.165021Z",
          "shell.execute_reply": "2023-09-25T20:19:05.163160Z",
          "shell.execute_reply.started": "2023-09-25T20:18:02.674470Z"
        },
        "id": "vtnGIQgtgSec",
        "outputId": "07500425-e22c-4b4d-eed7-0548e475ab94",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "130/130 [==============================] - 37s 272ms/step - loss: 0.4217 - accuracy: 0.8040 - val_loss: 9.8525 - val_accuracy: 0.0501\n",
            "Epoch 2/5\n",
            "130/130 [==============================] - 37s 283ms/step - loss: 0.2658 - accuracy: 0.8862 - val_loss: 13.9665 - val_accuracy: 0.0511\n",
            "Epoch 3/5\n",
            "130/130 [==============================] - 36s 276ms/step - loss: 0.2302 - accuracy: 0.9062 - val_loss: 12.8478 - val_accuracy: 0.0328\n",
            "Epoch 4/5\n",
            "130/130 [==============================] - 35s 267ms/step - loss: 0.2251 - accuracy: 0.9002 - val_loss: 10.1888 - val_accuracy: 0.0444\n",
            "Epoch 5/5\n",
            "130/130 [==============================] - 36s 274ms/step - loss: 0.2035 - accuracy: 0.9142 - val_loss: 13.7837 - val_accuracy: 0.0444\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c7720239090>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_tensor,y_tensor,validation_split=0.2,epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8oSrB6egSec"
      },
      "source": [
        "Nous observons une divergence notable entre l'accuracy de l'entraînement et celle de la validation, indiquant un overfitting significatif du modèle. Cela signifie que bien que le modèle ait appris à perfection les données d'entraînement, il échoue à généraliser son apprentissage à de nouvelles données inconnues, mises à l'épreuve durant la phase de validation.\n",
        "\n",
        "Analyse\n",
        "Cette situation pourrait découler de plusieurs raisons. Premièrement, il est possible que le modèle choisi ne soit pas le plus adapté à la nature de nos données. Un modèle trop complexe avec un grand nombre de paramètres peut facilement mémoriser les données d'entraînement mais sera inefficace pour interpréter de nouvelles données. Deuxièmement, il se pourrait également que la préparation des données ait été suboptimale, avec des choix de dimensionnalité ou d'échantillonnage qui n’alignent pas bien avec les propriétés intrinsèques des données."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
